<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SoundWatch Client</title>
    <script src="https://cdn.socket.io/4.4.1/socket.io.min.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            padding: 20px;
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
        }
        .status {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
            padding: 10px;
            border-radius: 4px;
            background-color: #f8f9fa;
        }
        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 10px;
            background-color: #dc3545;
        }
        .status-indicator.connected {
            background-color: #28a745;
        }
        .status-text {
            font-weight: 500;
        }
        .predictions {
            margin-top: 20px;
            border: 1px solid #dee2e6;
            border-radius: 4px;
            overflow: hidden;
        }
        .prediction-item {
            padding: 15px;
            border-bottom: 1px solid #dee2e6;
            transition: background-color 0.3s;
        }
        .prediction-item:last-child {
            border-bottom: none;
        }
        .prediction-item:hover {
            background-color: #f8f9fa;
        }
        .prediction-header {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
        }
        .prediction-label {
            font-weight: bold;
            font-size: 18px;
            color: #2c3e50;
        }
        .prediction-time {
            color: #6c757d;
            font-size: 14px;
        }
        .prediction-details {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 5px;
        }
        .prediction-detail {
            background-color: #e9ecef;
            padding: 5px 10px;
            border-radius: 4px;
            font-size: 14px;
        }
        .prediction-text {
            margin-top: 10px;
            font-style: italic;
            color: #495057;
        }
        .controls {
            margin: 20px 0;
            display: flex;
            gap: 10px;
        }
        button {
            padding: 8px 16px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #0069d9;
        }
        button:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        .clear-btn {
            background-color: #dc3545;
        }
        .clear-btn:hover {
            background-color: #c82333;
        }
        .server-url {
            width: 100%;
            padding: 8px;
            margin-bottom: 10px;
            border: 1px solid #ced4da;
            border-radius: 4px;
        }
        .no-predictions {
            text-align: center;
            padding: 20px;
            color: #6c757d;
        }
        .audio-controls {
            margin-top: 20px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border: 1px solid #dee2e6;
        }
        .audio-controls h3 {
            margin-top: 0;
            color: #2c3e50;
        }
        .audio-btn {
            background-color: #28a745;
        }
        .audio-btn:hover {
            background-color: #218838;
        }
        .audio-btn.recording {
            background-color: #dc3545;
        }
        .audio-status {
            margin-top: 10px;
            font-style: italic;
        }
        .engine-selector {
            margin: 10px 0;
            padding: 10px;
            background-color: #f5f5f5;
            border-radius: 5px;
        }
        .engine-selector h3 {
            margin-top: 0;
        }
        .engine-button {
            padding: 8px 15px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-weight: bold;
        }
        .engine-button.active {
            background-color: #4CAF50;
            color: white;
        }
        .engine-button:not(.active) {
            background-color: #e0e0e0;
            color: #333;
        }
        .engine-info {
            margin-top: 10px;
            font-size: 0.9em;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>SoundWatch Client</h1>
        
        <div class="status">
            <div id="status-indicator" class="status-indicator"></div>
            <div id="status-text" class="status-text">Disconnected</div>
        </div>
        
        <div class="controls">
            <input type="text" id="server-url" class="server-url" value="http://localhost:8080" placeholder="Server URL (e.g., http://localhost:8080)">
            <button id="connect-btn">Connect</button>
            <button id="disconnect-btn" disabled>Disconnect</button>
            <button id="clear-btn" class="clear-btn">Clear Predictions</button>
        </div>
        
        <div class="audio-controls">
            <h3>Test Audio</h3>
            <button id="audio-btn" class="audio-btn" disabled>Start Recording</button>
            <div id="audio-status" class="audio-status">Connect to server to enable recording</div>
        </div>
        
        <div class="engine-selector">
            <h3>Speech Recognition Engine</h3>
            <div class="engine-buttons">
                <button id="engineAuto" class="engine-button active" data-engine="auto">Auto (Google+Vosk)</button>
                <button id="engineGoogle" class="engine-button" data-engine="google">Google Only</button>
                <button id="engineVosk" class="engine-button" data-engine="vosk">Vosk Only (Offline)</button>
            </div>
            <div class="engine-info">
                <p id="engineInfo">Using Auto mode: Google Speech API with Vosk fallback</p>
            </div>
        </div>
        
        <h2>Sound Predictions</h2>
        <div id="predictions" class="predictions">
            <div class="no-predictions">No predictions received yet</div>
        </div>
    </div>

    <script>
        let socket = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        
        const statusIndicator = document.getElementById('status-indicator');
        const statusText = document.getElementById('status-text');
        const connectBtn = document.getElementById('connect-btn');
        const disconnectBtn = document.getElementById('disconnect-btn');
        const clearBtn = document.getElementById('clear-btn');
        const serverUrlInput = document.getElementById('server-url');
        const predictionsContainer = document.getElementById('predictions');
        const audioBtn = document.getElementById('audio-btn');
        const audioStatus = document.getElementById('audio-status');
        
        // Connect to the server
        connectBtn.addEventListener('click', () => {
            const serverUrl = serverUrlInput.value.trim();
            if (!serverUrl) {
                alert('Please enter a valid server URL');
                return;
            }
            
            try {
                socket = io(serverUrl);
                
                socket.on('connect', () => {
                    statusIndicator.classList.add('connected');
                    statusText.textContent = 'Connected to server';
                    connectBtn.disabled = true;
                    disconnectBtn.disabled = false;
                    audioBtn.disabled = false;
                    audioStatus.textContent = 'Ready to record test audio';
                });
                
                socket.on('disconnect', () => {
                    statusIndicator.classList.remove('connected');
                    statusText.textContent = 'Disconnected from server';
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;
                    audioBtn.disabled = true;
                    audioStatus.textContent = 'Connect to server to enable recording';
                    stopRecording();
                });
                
                socket.on('sound_prediction', (data) => {
                    addPrediction(data);
                });
                
                socket.on('connect_error', (error) => {
                    console.error('Connection error:', error);
                    alert(`Failed to connect to server: ${error.message}`);
                    statusText.textContent = `Connection error: ${error.message}`;
                });
            } catch (error) {
                console.error('Error creating socket:', error);
                alert(`Error creating socket: ${error.message}`);
            }
        });
        
        // Disconnect from the server
        disconnectBtn.addEventListener('click', () => {
            if (socket) {
                socket.disconnect();
                socket = null;
            }
        });
        
        // Clear predictions
        clearBtn.addEventListener('click', () => {
            predictionsContainer.innerHTML = '<div class="no-predictions">No predictions received yet</div>';
        });
        
        // Handle audio recording
        audioBtn.addEventListener('click', () => {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        });
        
        // Add a prediction to the UI
        function addPrediction(data) {
            // Remove "no predictions" message if it exists
            const noPredictions = document.querySelector('.no-predictions');
            if (noPredictions) {
                noPredictions.remove();
            }
            
            const now = new Date();
            const timeString = now.toLocaleTimeString();
            
            const predictionItem = document.createElement('div');
            predictionItem.className = 'prediction-item';
            
            const predictionHeader = document.createElement('div');
            predictionHeader.className = 'prediction-header';
            
            const predictionLabel = document.createElement('div');
            predictionLabel.className = 'prediction-label';
            predictionLabel.textContent = data.label || 'Unknown Sound';
            
            const predictionTime = document.createElement('div');
            predictionTime.className = 'prediction-time';
            predictionTime.textContent = timeString;
            
            predictionHeader.appendChild(predictionLabel);
            predictionHeader.appendChild(predictionTime);
            
            const predictionDetails = document.createElement('div');
            predictionDetails.className = 'prediction-details';
            
            // Add confidence
            const confidenceDetail = document.createElement('div');
            confidenceDetail.className = 'prediction-detail';
            confidenceDetail.textContent = `Confidence: ${(data.confidence * 100).toFixed(1)}%`;
            predictionDetails.appendChild(confidenceDetail);
            
            // Add dB level if available
            if (data.db_level !== undefined) {
                const dbDetail = document.createElement('div');
                dbDetail.className = 'prediction-detail';
                dbDetail.textContent = `dB Level: ${data.db_level.toFixed(1)} dB`;
                predictionDetails.appendChild(dbDetail);
            }
            
            predictionItem.appendChild(predictionHeader);
            predictionItem.appendChild(predictionDetails);
            
            // Add details text if available
            if (data.details) {
                const predictionText = document.createElement('div');
                predictionText.className = 'prediction-text';
                predictionText.textContent = data.details;
                predictionItem.appendChild(predictionText);
            }
            
            // Add to the beginning of the list
            predictionsContainer.insertBefore(predictionItem, predictionsContainer.firstChild);
        }
        
        // Start audio recording
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.addEventListener('dataavailable', event => {
                    audioChunks.push(event.data);
                });
                
                mediaRecorder.addEventListener('stop', () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    processAudioBlob(audioBlob);
                });
                
                // Start recording
                mediaRecorder.start();
                isRecording = true;
                audioBtn.textContent = 'Stop Recording';
                audioBtn.classList.add('recording');
                audioStatus.textContent = 'Recording audio...';
                
                // Automatically stop after 5 seconds
                setTimeout(() => {
                    if (isRecording) {
                        stopRecording();
                    }
                }, 5000);
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                alert(`Error accessing microphone: ${error.message}`);
                audioStatus.textContent = `Error: ${error.message}`;
            }
        }
        
        // Stop audio recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                audioBtn.textContent = 'Start Recording';
                audioBtn.classList.remove('recording');
                audioStatus.textContent = 'Processing audio...';
            }
        }
        
        // Process and send the audio blob to the server
        function processAudioBlob(audioBlob) {
            const fileReader = new FileReader();
            
            fileReader.onload = function() {
                const arrayBuffer = this.result;
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                audioContext.decodeAudioData(arrayBuffer, (audioBuffer) => {
                    // Convert to mono if needed
                    const numChannels = audioBuffer.numberOfChannels;
                    const sampleRate = audioBuffer.sampleRate;
                    const length = audioBuffer.length;
                    
                    // Create a mono audio buffer
                    let monoData = new Float32Array(length);
                    
                    // If stereo, average the channels
                    if (numChannels === 2) {
                        const left = audioBuffer.getChannelData(0);
                        const right = audioBuffer.getChannelData(1);
                        
                        for (let i = 0; i < length; i++) {
                            monoData[i] = (left[i] + right[i]) / 2;
                        }
                    } else {
                        // Just copy the data if already mono
                        monoData = audioBuffer.getChannelData(0);
                    }
                    
                    // Convert to array for JSON serialization
                    const audioArray = Array.from(monoData);
                    
                    // Send to server
                    if (socket && socket.connected) {
                        socket.emit('audio_data', {
                            audio: audioArray,
                            sample_rate: sampleRate
                        });
                        
                        audioStatus.textContent = `Sent ${audioArray.length} audio samples to server`;
                    } else {
                        audioStatus.textContent = 'Error: Not connected to server';
                    }
                }, (error) => {
                    console.error('Error decoding audio data:', error);
                    audioStatus.textContent = `Error decoding audio: ${error.message}`;
                });
            };
            
            fileReader.onerror = function(error) {
                console.error('Error reading audio file:', error);
                audioStatus.textContent = `Error reading audio: ${error.message}`;
            };
            
            fileReader.readAsArrayBuffer(audioBlob);
        }

        // Add code for speech engine selection
        const engineButtons = document.querySelectorAll('.engine-button');
        const engineInfo = document.getElementById('engineInfo');

        // Update UI to show currently selected engine
        function updateEngineUI(selectedEngine) {
            engineButtons.forEach(button => {
                const engine = button.getAttribute('data-engine');
                if (engine === selectedEngine) {
                    button.classList.add('active');
                } else {
                    button.classList.remove('active');
                }
            });

            // Update info text
            switch(selectedEngine) {
                case 'auto':
                    engineInfo.textContent = 'Using Auto mode: Google Speech API with Vosk fallback';
                    break;
                case 'google':
                    engineInfo.textContent = 'Using Google Speech API only (requires internet)';
                    break;
                case 'vosk':
                    engineInfo.textContent = 'Using Vosk only (offline mode, may be less accurate)';
                    break;
            }
        }

        // Handle engine selection
        engineButtons.forEach(button => {
            button.addEventListener('click', function() {
                const engine = this.getAttribute('data-engine');
                
                // Send request to change engine
                fetch('/api/toggle-speech-recognition', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ speech_engine: engine })
                })
                .then(response => response.json())
                .then(data => {
                    if (data.success) {
                        updateEngineUI(engine);
                        addResult('System', `Speech recognition engine changed to: ${engine}`, 'info');
                    } else {
                        addResult('Error', `Failed to change speech engine: ${data.message}`, 'error');
                    }
                })
                .catch(error => {
                    addResult('Error', `Error changing speech engine: ${error}`, 'error');
                });
            });
        });

        // Get initial engine setting on page load
        fetch('/status')
            .then(response => response.json())
            .then(data => {
                if (data.speech_recognition) {
                    updateEngineUI(data.speech_recognition);
                }
            })
            .catch(error => {
                console.error('Error fetching server status:', error);
            });
    </script>
</body>
</html> 